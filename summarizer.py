import os
import google.generativeai as genai
from dotenv import load_dotenv


load_dotenv()
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
genai.configure(api_key=GEMINI_API_KEY)
model = genai.GenerativeModel('gemini-pro')

def get_topic_emoji(topic):
    # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å —Ç–µ–º –∏ –∏—Ö —ç–º–æ–¥–∑–∏
    emoji_map = {
        # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç–µ–º—ã
        "—Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞": "üíª",
        "–∫–æ–¥": "üë®‚Äçüíª",
        "–±–∞–≥": "üêõ",
        "–æ—à–∏–±–∫–∞": "‚ùå",
        "—Ç–µ—Å—Ç": "üß™",
        "api": "üîå",
        "–±–æ—Ç": "ü§ñ",
        "–±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö": "üíæ",
        "—Å–µ—Ä–≤–µ—Ä": "üñ•Ô∏è",
        # –ë–∏–∑–Ω–µ—Å –∏ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è
        "–≤—Å—Ç—Ä–µ—á–∞": "üìÖ",
        "–ø—Ä–æ–µ–∫—Ç": "üìã",
        "–∑–∞–¥–∞—á–∞": "‚úÖ",
        "–¥–µ–¥–ª–∞–π–Ω": "‚è∞",
        "–ø–ª–∞–Ω": "üìä",
        "—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞": "üìà",
        "–æ—Ç—á–µ—Ç": "üìë",
        # –ö–æ–º–º—É–Ω–∏–∫–∞—Ü–∏—è
        "–æ–±—Å—É–∂–¥–µ–Ω–∏–µ": "üí¨",
        "–≤–æ–ø—Ä–æ—Å": "‚ùì",
        "—Ä–µ—à–µ–Ω–∏–µ": "üí°",
        "–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ": "‚ú®",
        "–ø—Ä–æ–±–ª–µ–º–∞": "‚ö†Ô∏è",
        # –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å
        "–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å": "üîí",
        "–¥–æ—Å—Ç—É–ø": "üîë",
        "–ø–∞—Ä–æ–ª—å": "üîê",
        # –û–±—â–∏–µ —Ç–µ–º—ã
        "–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ": "üÜï",
        "–∏–∑–º–µ–Ω–µ–Ω–∏–µ": "üîÑ",
        "–Ω–∞—Å—Ç—Ä–æ–π–∫–∞": "‚öôÔ∏è",
        "–¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è": "üìö",
        "default": "üìù"
    }
    
    for key, emoji in emoji_map.items():
        if key.lower() in topic.lower():
            return emoji
    return emoji_map["default"]

async def summarize_threads(storage, chat_id, threads, since_date=None):
    summaries = []
    links = []
    last_summary_time = since_date or await storage.get_last_summary_time(chat_id)

    def clean_text(text):
        return text.replace('<', '&lt;').replace('>', '&gt;').replace('&', '&amp;')

    for thread_id in threads:
        messages = await storage.get_messages_since(chat_id, thread_id, last_summary_time)
        if not messages:
            continue

        # –°–æ–±–∏—Ä–∞–µ–º —Å—Å—ã–ª–∫–∏ –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏–π
        for msg in messages:
            text = msg.get('text', '')
            if text:
                words = text.split()
                for word in words:
                    if word.startswith(('http://', 'https://', 't.me/')):
                        links.append(word)

        text_block = "\n".join([f"{m['user']}: {clean_text(m['text'])}" for m in messages])
        prompt = (
            "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –¥–∏–∞–ª–æ–≥ –∏ –æ–ø—Ä–µ–¥–µ–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –≥–ª–∞–≤–Ω—ã—Ö —Ç–µ–º –æ–±—Å—É–∂–¥–µ–Ω–∏—è. "
            "–û—Ç–≤–µ—Ç—å –¢–û–õ–¨–ö–û –æ—Å–Ω–æ–≤–Ω—ã–º–∏ —Ç–µ–º–∞–º–∏ –≤ 3-4 —Å–ª–æ–≤–∞ –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞.\n\n"
            f"{text_block}"
        )

        response = await model.generate_content_async(prompt)
        topic = clean_text(response.text.strip())
        emoji = get_topic_emoji(topic)
        msg_count = len(messages)
        thread_url = f"https://t.me/c/{str(chat_id)[4:]}/{thread_id}" if thread_id else None

        summary_item = {
            "emoji": emoji,
            "topic": topic,
            "message_count": msg_count,
            "thread_id": thread_id,
            "url": thread_url
        }
        summaries.append(summary_item)

    summaries.sort(key=lambda x: x["message_count"], reverse=True)
    clean_links = [clean_text(link) for link in set(links)]
    return {
        "topics": summaries,
        "links": clean_links
    }