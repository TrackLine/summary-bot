import os
import logging
from dotenv import load_dotenv

load_dotenv()
SUMMARIZER_PROVIDER = os.getenv("SUMMARIZER_PROVIDER", "gemini").lower()
SUMMARIZER_MODEL = os.getenv("SUMMARIZER_MODEL", "models/gemini-1.0-pro")

# --- Gemini ---
if SUMMARIZER_PROVIDER == "gemini":
    import google.generativeai as genai
    GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
    genai.configure(api_key=GEMINI_API_KEY)
    try:
        available_models = [m.name for m in genai.list_models()]
        logging.info(f"–î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ Gemini: {available_models}")
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π Gemini: {e}")
    model = genai.GenerativeModel(SUMMARIZER_MODEL)

# --- OpenAI ---
if SUMMARIZER_PROVIDER == "openai":
    from openai import OpenAI
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
    openai_client = OpenAI(api_key=OPENAI_API_KEY)

def get_topic_emoji(topic):
    # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å —Ç–µ–º –∏ –∏—Ö —ç–º–æ–¥–∑–∏
    emoji_map = {
        # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç–µ–º—ã
        "—Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞": "üíª",
        "–∫–æ–¥": "üë®‚Äçüíª",
        "–±–∞–≥": "üêõ",
        "–æ—à–∏–±–∫–∞": "‚ùå",
        "—Ç–µ—Å—Ç": "üß™",
        "api": "üîå",
        "–±–æ—Ç": "ü§ñ",
        "–±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö": "üíæ",
        "—Å–µ—Ä–≤–µ—Ä": "üñ•Ô∏è",
        # –ë–∏–∑–Ω–µ—Å –∏ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è
        "–≤—Å—Ç—Ä–µ—á–∞": "üìÖ",
        "–ø—Ä–æ–µ–∫—Ç": "üìã",
        "–∑–∞–¥–∞—á–∞": "‚úÖ",
        "–¥–µ–¥–ª–∞–π–Ω": "‚è∞",
        "–ø–ª–∞–Ω": "üìä",
        "—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞": "üìà",
        "–æ—Ç—á–µ—Ç": "üìë",
        # –ö–æ–º–º—É–Ω–∏–∫–∞—Ü–∏—è
        "–æ–±—Å—É–∂–¥–µ–Ω–∏–µ": "üí¨",
        "–≤–æ–ø—Ä–æ—Å": "‚ùì",
        "—Ä–µ—à–µ–Ω–∏–µ": "üí°",
        "–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ": "‚ú®",
        "–ø—Ä–æ–±–ª–µ–º–∞": "‚ö†Ô∏è",
        # –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å
        "–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å": "üîí",
        "–¥–æ—Å—Ç—É–ø": "üîë",
        "–ø–∞—Ä–æ–ª—å": "üîê",
        # –û–±—â–∏–µ —Ç–µ–º—ã
        "–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ": "üÜï",
        "–∏–∑–º–µ–Ω–µ–Ω–∏–µ": "üîÑ",
        "–Ω–∞—Å—Ç—Ä–æ–π–∫–∞": "‚öôÔ∏è",
        "–¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è": "üìö",
        "default": "üìù"
    }
    
    for key, emoji in emoji_map.items():
        if key.lower() in topic.lower():
            return emoji
    return emoji_map["default"]

async def summarize_threads(storage, chat_id, threads, since_date=None):
    summaries = []
    links = []
    last_summary_time = since_date or await storage.get_last_summary_time(chat_id)

    def clean_text(text):
        return text.replace('<', '&lt;').replace('>', '&gt;').replace('&', '&amp;')

    for thread_id in threads:
        messages = await storage.get_messages_since(chat_id, thread_id, last_summary_time)
        if not messages:
            continue

        # –°–æ–±–∏—Ä–∞–µ–º —Å—Å—ã–ª–∫–∏ –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏–π
        for msg in messages:
            text = msg.get('text', '')
            if text:
                words = text.split()
                for word in words:
                    if word.startswith(('http://', 'https://', 't.me/')):
                        links.append(word)

        text_block = "\n".join([f"{m['user']}: {clean_text(m['text'])}" for m in messages])
        prompt = (
            "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –¥–∏–∞–ª–æ–≥ –∏ –≤—ã–¥–µ–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –≥–ª–∞–≤–Ω—ã—Ö —Ç–µ–º –æ–±—Å—É–∂–¥–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ —Ä–µ–∞–ª—å–Ω–æ —Å–≤—è–∑–∞–Ω—ã —Å –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–º–∞—Ç–∏–∫–æ–π —á–∞—Ç–∞ –∏ –æ–±—Å—É–∂–¥–∞–ª–∏—Å—å –±–æ–ª–µ–µ 10-15 —Å–æ–æ–±—â–µ–Ω–∏–π. "
            "–ò–≥–Ω–æ—Ä–∏—Ä—É–π —Ñ–ª—É–¥, —Ç—Ä–æ–ª–ª–∏–Ω–≥, —à—É—Ç–∫–∏ –∏ –æ—Ñ—Ñ—Ç–æ–ø. –û—Ç–≤–µ—Ç—å —Ç–æ–ª—å–∫–æ —Å–ø–∏—Å–∫–æ–º —Ç–µ–º (–∫–∞–∂–¥–∞—è –≤ 3-4 —Å–ª–æ–≤–∞, –±–µ–∑ –ª–∏—à–Ω–µ–≥–æ —Ç–µ–∫—Å—Ç–∞), –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏.\n\n"
            f"{text_block}"
        )

        if SUMMARIZER_PROVIDER == "gemini":
            response = model.generate_content(prompt)
            topic = clean_text(response.text.strip())
        elif SUMMARIZER_PROVIDER == "openai":
            completion = openai_client.chat.completions.create(
                model="gpt-4-turbo-preview",
                messages=[
                    {"role": "system", "content": "–í—ã ‚Äî –ø–æ–ª–µ–∑–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫, –∫–æ—Ç–æ—Ä—ã–π –æ–±–æ–±—â–∞–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è —á–∞—Ç–∞. –°–¥–µ–ª–∞–π—Ç–µ –≤—Å–µ –≤–æ–∑–º–æ–∂–Ω–æ–µ, —á—Ç–æ–±—ã –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—å –ø–æ–ª–µ–∑–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–æ–º, —á—Ç–æ –æ–±—Å—É–∂–¥–∞–ª–æ—Å—å –≤ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏—è—Ö —á–∞—Ç–∞."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=100,
            )
            topic = clean_text(completion.choices[0].message.content.strip())
        else:
            topic = "[–ü—Ä–æ–≤–∞–π–¥–µ—Ä —Å–∞–º–º–∞—Ä–∏ –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω]"
        emoji = get_topic_emoji(topic)
        msg_count = len(messages)
        thread_url = f"https://t.me/c/{str(chat_id)[4:]}/{thread_id}" if thread_id else None

        summary_item = {
            "emoji": emoji,
            "topic": topic,
            "message_count": msg_count,
            "thread_id": thread_id,
            "url": thread_url
        }
        summaries.append(summary_item)

    summaries.sort(key=lambda x: x["message_count"], reverse=True)
    clean_links = [clean_text(link) for link in set(links)]
    return {
        "topics": summaries,
        "links": clean_links
    }